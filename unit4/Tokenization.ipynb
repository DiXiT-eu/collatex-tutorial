{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization, or \"Tokenize Your Own\"\n",
    "\n",
    "Why tokenize yourself?\n",
    "\n",
    "By default CollateX \"splits on whitespace and interpunction\". This often that you will get words to be your unit of collation.\n",
    "\n",
    "But what about \"can't\", \"A'dam\", \"Peter's\"?\n",
    "\n",
    "Tokenization defines your *unit of comparison* and thus gives you more control over the comparison\n",
    "\n",
    "Unfortunately this means learning how to offer a *pretokenized* *data structure* to CollateX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretokenized text as JSON\n",
    "\n",
    "Assert:\n",
    "\n",
    "    witness_A = \"Peter's cat\"\n",
    "    witness_B = \"Peter's dog\"\n",
    "\n",
    "Problem: \"Peter's cat\" will be tokenizes as \"Peter\", \"'\", \"s\" , \"cat\"\n",
    "\n",
    "We will use JSON to tell CollateX to 'read' and collate it differently\n",
    "\n",
    "JSON data is a mixture of arrays and objects:\n",
    "\n",
    "Arrays look like this: \n",
    "\n",
    "    [ \"i\", \"am\", \"the\", \"words\", \"in\", \"an\", \"array\" ]\n",
    "\n",
    "Onbjects look like:\n",
    "\n",
    "    { \"a_variable_name\": \"My first value\", \"another_varible\": \"Another thingy\" }\n",
    "    \n",
    "In JSON you may combine this:\n",
    "\n",
    "    { \"a_witness_object\": { \"siglum\": \"A\", \"tokens\": [] } } \n",
    "    \n",
    "Or the same, layed out so that it is somewhat easier to read:\n",
    "\n",
    "    { \"a_witness_object\":\n",
    "        { \n",
    "            \"siglum\": \"A\",\n",
    "            \"tokens\": []\n",
    "        }\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try the good old fashion way…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collatex import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collation = Collation()\n",
    "collation.add_plain_witness( \"A\", \"Peter's cat\")\n",
    "collation.add_plain_witness( \"B\", \"Peter's dog\" )\n",
    "alignment_table = collate( collation, layout='vertical', segmentation=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|   A   |   B   |\n",
      "+-------+-------+\n",
      "| Peter | Peter |\n",
      "+-------+-------+\n",
      "|   '   |   '   |\n",
      "+-------+-------+\n",
      "|   s   |   s   |\n",
      "+-------+-------+\n",
      "|  cat  |  dog  |\n",
      "+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "print( alignment_table )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm.. indeed not quite what we want, thus…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_a = [ { \"t\": \"Peter's\" }, { \"t\": \"cat\" } ]\n",
    "tokens_b = [ { \"t\": \"Peter's\" }, { \"t\": \"dog\" } ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "witness_a = { \"id\": \"A\", \"tokens\": tokens_a }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'A', 'tokens': [{'t': \"Peter's\"}, {'t': 'cat'}]}\n"
     ]
    }
   ],
   "source": [
    "print( witness_a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "witness_b = { \"id\": \"A\", \"tokens\": tokens_b }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JSON_input = { \"witnesses\": [ witness_a, witness_b ] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = collate_pretokenized_json( JSON_input, output='table' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+\n",
      "| A | Peter's | cat |\n",
      "| A | Peter's | dog |\n",
      "+---+---------+-----+\n"
     ]
    }
   ],
   "source": [
    "print( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
